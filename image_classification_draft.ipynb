{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from image_classification_X_ray import get_large_contours\n",
    "from image_classification_X_ray import is_X_ray\n",
    "\n",
    "from image_classification_StraightLine import get_straight_line_cnt\n",
    "\n",
    "from image_classification_column_hist import get_column_hist_and_fitting\n",
    "\n",
    "from image_classification_text_using_SWT import text_area_div_likely_text_area\n",
    "\n",
    "results_set=['text', 'form', 'X-ray', 'others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_for_all_classify_result(results_set):\n",
    "    for result in results_set:\n",
    "        isExists=os.path.exists(classify_results_path+result)\n",
    "        if not isExists:\n",
    "            os.makedirs(classify_results_path+result)\n",
    "            print('folder %s has been made.'%result)\n",
    "        else:\n",
    "            print('folder %s is exist.'%result)\n",
    "\n",
    "class CLASSIFY_RULE:\n",
    "    def __init__(self, LINE_CNT__THRESHOLD, TEXT_RATE_THRESHOLD):#经验值分别为9和1.0\n",
    "        #['no_black_contour', 'has_black_contour', 'has_black_stripe', 'sensitive_info', 'unk']\n",
    "        self.LINE_CNT__THRESHOLD = LINE_CNT__THRESHOLD\n",
    "        self.TEXT_RATE_THRESHOLD = TEXT_RATE_THRESHOLD\n",
    "        \n",
    "    def classify(self, img_id, black_area_classify_result, straight_lines_cnt, text_rate):\n",
    "        if text_rate>=self.TEXT_RATE_THRESHOLD:\n",
    "            classify_result = 'text'\n",
    "        elif black_area_classify_result == 'has_black_contour':\n",
    "            classify_result = 'X-ray'\n",
    "        elif straight_lines_cnt>=self.LINE_CNT__THRESHOLD or black_area_classify_result == 'has_black_stripe':\n",
    "            classify_result = 'form'\n",
    "        else:\n",
    "            classify_result = 'others'\n",
    "            \n",
    "        return classify_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "folder text is exist.\n",
      "folder form is exist.\n",
      "folder X-ray is exist.\n",
      "folder others is exist.\n",
      "img_1000000.png no_black_contour 0 0.7981490099693865\n",
      "img_1000001.png has_black_stripe 0 0.755346116927198\n",
      "img_1000002.png has_black_stripe 0 0.5728119016876506\n",
      "img_1000003.png has_black_stripe 0 0.7962160033734819\n",
      "img_1000004.png has_black_stripe 0 0.7390099323819792\n",
      "img_1000005.png has_black_stripe 0 0.5613152294403403\n",
      "img_1000006.png has_black_contour 0 0.724011518724172\n",
      "img_1000007.png has_black_contour 0 0.7289651528130519\n",
      "img_1000008.png has_black_contour 0 0.6652909992226428\n",
      "img_1000009.png has_black_contour 0 0.8283164978076756\n",
      "img_1000010.png has_black_contour 0 0.9113635670752832\n",
      "img_1000011.png no_black_contour 0 1.2982051558726946\n",
      "img_1000012.png has_black_contour 0 0.57302275752682\n",
      "img_1000013.png has_black_contour 0 0.7648009193130064\n",
      "img_1000014.png no_black_contour 0 1.3747309461244088\n",
      "img_1000015.png no_black_contour 0 1.18318869865035\n",
      "img_1000016.png has_black_contour 0 0.4129851039478209\n",
      "img_1000017.png no_black_contour 0 0.40621274932558443\n",
      "img_1000018.png no_black_contour 0 1.5211701108210154\n",
      "img_1000019.png no_black_contour 0 1.3759877693964893\n",
      "img_1000020.png no_black_contour 0 1.3966112436633324\n",
      "img_1000021.png no_black_contour 0 1.3972459961020252\n",
      "img_1000022.png has_black_stripe 0 0.8260782834442295\n",
      "img_1000023.png has_black_stripe 0 0.7326939763478787\n",
      "img_1000024.png has_black_stripe 0 0.6572594390284704\n",
      "img_1000025.png has_black_stripe 0 0.7907604468989913\n",
      "img_1000026.png sensitive_info 0 0.4645723893341602\n",
      "img_1000027.png sensitive_info 4 0.7737927048943483\n",
      "img_1000028.png sensitive_info 6 0.7315314719036318\n",
      "img_1000029.png sensitive_info 4 0.9949998332692737\n",
      "img_1000030.png sensitive_info 33 0.16990730389046718\n",
      "img_1000031.png sensitive_info 14 0.3044365852957244\n",
      "img_1000032.png sensitive_info 9 0.4275896159893327\n",
      "img_1000033.png sensitive_info 14 0.5471798180869965\n",
      "img_1000034.png sensitive_info 10 0.4655580288072827\n",
      "img_1000035.png sensitive_info 14 0.7980032365772138\n",
      "img_1000036.png sensitive_info 28 0.6604356988781114\n",
      "img_1000037.png sensitive_info 16 0.8579081599482863\n",
      "img_1000038.png sensitive_info 165 0.10589605458929763\n",
      "img_1000039.png sensitive_info 6 0.9707476832750267\n",
      "img_1000040.png has_black_contour 8 0.03396585768180692\n",
      "img_1000041.png sensitive_info 5 0.7093002695186708\n",
      "running time:  3.17 minutes.\n"
     ]
    }
   ],
   "source": [
    "img_path = '../OCR_data/output/'\n",
    "classify_results_path = './'\n",
    "\n",
    "start_time=time.time()#计时开始\n",
    "print('running...')\n",
    "\n",
    "classify_rule = CLASSIFY_RULE(LINE_CNT__THRESHOLD=8, TEXT_RATE_THRESHOLD=1.0)\n",
    "\n",
    "\n",
    "#支持读取的图片不是按照img_10000xx.png格式命名，支持命名的数字非连续，支持png之外的其他图片格式。支持文件夹里面有其他格式的文件，例如txt。\n",
    "make_folder_for_all_classify_result(results_set)\n",
    "likely_img_file = os.listdir(img_path)\n",
    "for img_file in likely_img_file:\n",
    "    if img_file[-3:] not in ['bmp','png','jpg', 'jpeg', 'BMP', 'PNG', 'JPG', 'JPEG']:#非该后缀名列表中的文件不处理，图片格式不够可以加\n",
    "        continue\n",
    "    else:\n",
    "        img = cv2.imread(img_path + img_file)\n",
    "    \n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_height, img_width = gray_img.shape[:2]\n",
    "\n",
    "        bin_threshold, bin_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "        #计算连通域，并且进行滤波，每个汉字中笔画包围的小区域去除，保留外层连通域，并进行从大到小的排列\n",
    "        areas_sorted, boxs_hor_sorted = get_large_contours(bin_img)\n",
    "        black_area_classify_result = is_X_ray(bin_img, areas_sorted, boxs_hor_sorted)\n",
    "\n",
    "        #下面注释的代码可以画出当前找到的连通域，很花时间，非调试不使用\n",
    "#         tmp_img = gray_img - gray_img\n",
    "#         cv2.drawContours(tmp_img,boxs_hor_sorted,-1,(100,100,100),5)\n",
    "#         PIL_img_show(tmp_img)\n",
    "    \n",
    "        #计算图像中的直线数量，有阈值设定，在image_classification_StraightLine.py文件中。已经调节好，不轻易更改\n",
    "        straight_lines_cnt = get_straight_line_cnt(bin_img)\n",
    "\n",
    "        #计算文字的占有率，即文字区域面积除以总的连通域面积，经过尝试是文字居多的图片该值大于1\n",
    "        text_rate = text_area_div_likely_text_area(bin_img, gray_img)\n",
    "\n",
    "        black_area_classify_set = ['no_black_contour', 'has_black_contour', 'has_black_stripe', 'sensitive_info', 'unk']\n",
    "        print(img_file, black_area_classify_result, straight_lines_cnt, text_rate)\n",
    "\n",
    "        #按规则分类，规则在 CLASSIFY_RULE 类中定义\n",
    "        classify_result = classify_rule.classify(img_file, black_area_classify_result, straight_lines_cnt, text_rate)\n",
    "        #print(img_file, classify_result)\n",
    "\n",
    "        #经过测试，此处复制消耗时间大约是0.1秒，不影响性能\n",
    "        #shutil.copyfile(img_path+img_file, classify_results_path+classify_result+'/'+img_file)      #复制文件\n",
    "\n",
    "        #下面的指标需要进一步设计，目前的鲁棒性不算很高，一般般，无法完全区分出表格和某些文字，to do\n",
    "        #curve_fitting_res, has_several_wave, _ = get_column_hist_and_fitting(bin_img)\n",
    "        #print(img_id, black_area_classify_result, straight_lines_cnt, curve_fitting_res, has_several_wave, text_rate_metric)\n",
    "\n",
    "#计算总体耗时\n",
    "#实际实践中，具体消耗是大约一张1M的图片处理耗时4.5秒。\n",
    "print('running time: %5.2f minutes.'%((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "0 others\n",
      "1 form\n",
      "2 form\n",
      "3 form\n",
      "4 form\n",
      "5 form\n",
      "6 X-ray\n",
      "7 X-ray\n",
      "8 X-ray\n",
      "9 X-ray\n",
      "10 X-ray\n",
      "11 text\n",
      "12 X-ray\n",
      "13 X-ray\n",
      "14 text\n",
      "15 text\n",
      "16 X-ray\n",
      "17 others\n",
      "18 text\n",
      "19 text\n",
      "20 text\n",
      "21 text\n",
      "22 form\n",
      "23 form\n",
      "24 form\n",
      "25 form\n",
      "26 others\n",
      "27 others\n",
      "28 others\n",
      "29 others\n",
      "30 form\n",
      "31 form\n",
      "32 form\n",
      "33 form\n",
      "34 form\n",
      "35 form\n",
      "36 form\n",
      "37 form\n",
      "38 form\n",
      "39 others\n",
      "40 X-ray\n",
      "41 others\n",
      "running time:  3.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "print('running...')\n",
    "\n",
    "classify_rule = CLASSIFY_RULE(LINE_CNT__THRESHOLD=8, TEXT_RATE_THRESHOLD=1.0)\n",
    "\n",
    "for img_id in range(42):\n",
    "    img_name = 'img_'+str(1000000+img_id)+'.png'\n",
    "    img = cv2.imread(img_path + img_name)\n",
    "    \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_height, img_width = gray_img.shape[:2]\n",
    "\n",
    "    bin_threshold, bin_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    \n",
    "    \n",
    "#     tmp_img = dilate_img - dilate_img\n",
    "#     cv2.drawContours(tmp_img,boxs_hor_sorted,-1,(100,100,100),5)\n",
    "#     PIL_img_show(tmp_img)\n",
    "    areas_sorted, boxs_hor_sorted = get_large_contours(bin_img)\n",
    "    black_area_classify_result = is_X_ray(bin_img, areas_sorted, boxs_hor_sorted)\n",
    "    \n",
    "    straight_lines_cnt = get_straight_line_cnt(bin_img)\n",
    "    \n",
    "    \n",
    "    text_rate = text_area_div_likely_text_area(bin_img, gray_img)\n",
    "    \n",
    "    black_area_classify_set = ['no_black_contour', 'has_black_contour', 'has_black_stripe', 'sensitive_info', 'unk']\n",
    "    #print(img_id, black_area_classify_result, straight_lines_cnt, text_rate)\n",
    "    \n",
    "    print(img_id, classify_rule.classify(img_id, black_area_classify_result, straight_lines_cnt, text_rate))\n",
    "    \n",
    "    \n",
    "    #curve_fitting_res, has_several_wave, _ = get_column_hist_and_fitting(bin_img)\n",
    "    #print(img_id, black_area_classify_result, straight_lines_cnt, curve_fitting_res, has_several_wave, text_rate_metric)\n",
    "    \n",
    "print('running time: %5.2f minutes.'%((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pillowfight\n",
    "def PIL_img_show(img):\n",
    "    Image.fromarray(img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = 'img_'+str(1000000+24)+'.png'\n",
    "img = cv2.imread(img_path + img_name)\n",
    "    \n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_height, img_width = gray_img.shape[:2]\n",
    "\n",
    "bin_threshold, bin_img = cv2.threshold(gray_img,0,100,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "#bin_img = gray_img[190:240, 550:750]\n",
    "\n",
    "a=Image.fromarray(bin_img)\n",
    "a.show()\n",
    "#SWT_OUTPUT_BW_TEXT\n",
    "#SWT_OUTPUT_GRAYSCALE_TEXT\n",
    "#SWT_OUTPUT_ORIGINAL_BOXES\n",
    "img_out = pillowfight.swt(a, output_type=pillowfight.SWT_OUTPUT_ORIGINAL_BOXES)\n",
    "img_out.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_threshold, bin_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(bin_img.shape)\n",
    "bin_img==np.ones((img_height, img_width))*254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2446, 3462) (2446, 3462)\n",
      "3462 2446\n",
      "(3462, 2446) [[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "(3462, 2446) [[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(a.size, img_out.size)\n",
    "\n",
    "x,y =bin_img.shape[:2]\n",
    "print(x,y)\n",
    "original_img_mask = np.uint8(np.ones((x,y))*255)\n",
    "print(original_img_mask.shape, original_img_mask)\n",
    "\n",
    "swt_out_img = np.array(img_out)[:,:,0]\n",
    "print(swt_out_img.shape, swt_out_img)\n",
    "b=np.uint8(swt_out_img==original_img_mask)\n",
    "print(b)\n",
    "Image.fromarray(255*b).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "swt_out_img = np.array(img_out)[:,:,2]\n",
    "PIL_img_show(swt_out_img)\n",
    "\n",
    "a=np.array([0,0,1,2])\n",
    "b=np.array([0,0,0,0])\n",
    "print(sum(a==b))\n",
    "\n",
    "print(np.array(img_out))\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
