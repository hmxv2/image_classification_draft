{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img_path = '../OCR_data/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIL_img_show(img):\n",
    "    Image.fromarray(img).show()\n",
    "\n",
    "def contours_filter(contours, hierarchy):#汉字的一个特点是文字内部有空洞，由此形成连通域，但是检测句子所在行的话应该去掉这部分\n",
    "    first_child = hierarchy[0][0][2]\n",
    "    next_child = first_child\n",
    "    all_children=[]\n",
    "    while(next_child!=-1):\n",
    "        all_children.append(next_child)\n",
    "        next_child = hierarchy[0][next_child][0]\n",
    "    contours_filtered = [contours[x] for x in all_children]\n",
    "    \n",
    "#     print(len(all_children), all_children)\n",
    "    return contours_filtered\n",
    "\n",
    "def get_large_contours(bin_img):#must be dilated\n",
    "    img_height, img_width = bin_img.shape[:2]\n",
    "    \n",
    "    kernel_size = (int(img_height/500), int(img_width/150))#经验值。水平因为文字距离近，所以腐蚀多一点，垂直因为文字离得远，腐蚀少一点也无大碍\n",
    "    kernel = np.ones(kernel_size,np.uint8)\n",
    "    dilate_img = cv2.dilate(bin_img,kernel,iterations = 1)\n",
    "    \n",
    "    # cv2.RETR_EXTERNAL表示只检测外轮廓\n",
    "    # cv2.RETR_LIST检测的轮廓不建立等级关系\n",
    "    # cv2.RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。\n",
    "    # cv2.RETR_TREE建立一个等级树结构的轮廓。\n",
    "    image, contours, hierarchy = cv2.findContours(dilate_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)#CHAIN_APPROX_SIMPLE\n",
    "\n",
    "    contours_filtered = contours_filter(contours, hierarchy)\n",
    "    if contours_filtered==[]:\n",
    "        return [],[]\n",
    "    \n",
    "    \n",
    "    areas=[]\n",
    "    rects=[]#矩形信息包括：矩形中心，高度，宽度，旋转角\n",
    "    boxs=[]#矩形信息包括：矩形四个点的坐标，经过rects信息计算而来，经过了计算把浮点数转化为图像坐标，矩形可以不是水平的。\n",
    "\n",
    "    for cnt in contours_filtered:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        areas.append(area)\n",
    "\n",
    "        rect = cv2.minAreaRect(cnt) # 得到最小外接矩形的（中心(x,y), (宽,高), 旋转角度）\n",
    "        rects.append(rect)\n",
    "\n",
    "        box = cv2.boxPoints(rect) # cv2.boxPoints(rect) for OpenCV 3.x 获取最小外接矩形的4个顶点\n",
    "        box = np.int0(box)\n",
    "        boxs.append(box)\n",
    "\n",
    "#     tmp_img = erosion_img-erosion_img\n",
    "#     cv2.drawContours(tmp_img,boxs,-1,(100,100,100),5)\n",
    "#     PIL_img_show(tmp_img)\n",
    "    \n",
    "    boxs_horizontal=[]#将boxs化为方向水平，但是如果句子是倾斜的则圈出的范围过于宽泛。\n",
    "    for box in boxs:\n",
    "        x1=min(box[0][0], box[1][0], box[2][0], box[3][0])\n",
    "        x2=max(box[0][0], box[1][0], box[2][0], box[3][0])\n",
    "        y1=min(box[0][1], box[1][1], box[2][1], box[3][1])\n",
    "        y2=max(box[0][1], box[1][1], box[2][1], box[3][1])\n",
    "        \n",
    "        rect_area = max(abs(x2-x1), abs(y2-y1))*min(abs(x2-x1),abs(y2-y1))\n",
    "        if rect_area/img_height/img_width<0.0005:#太小的区域，只能是噪点和零星的文字，忽略掉\n",
    "            continue\n",
    "        boxs_horizontal.append(np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2]]))\n",
    "    \n",
    "    if boxs_horizontal==[]:\n",
    "        return [],[]\n",
    "#     print(len(boxs_horizontal))\n",
    "\n",
    "    areas=[]\n",
    "    for cnt in boxs_horizontal:\n",
    "        areas.append( cv2.contourArea(cnt))\n",
    "    \n",
    "    zipped = zip(boxs_horizontal, areas)\n",
    "    zipped_sorted = sorted(zipped, key=lambda x:x[1], reverse=True)\n",
    "    boxs_hor_sorted, areas_sorted = zip(*zipped_sorted)\n",
    "    return list(areas_sorted), list(boxs_hor_sorted)\n",
    "    \n",
    "#     areas_sorted = areas.copy()\n",
    "#     areas_sorted.sort()\n",
    "#     areas_sorted = [x/(img_height*img_width)*100 for x in areas_sorted]\n",
    "\n",
    "#     return areas_sorted, boxs_horizontal\n",
    "\n",
    "def is_X_ray(bin_img, areas_sorted, boxs_hor_sorted, topK_chosen_rate=0.8, topK_average_threshold=3.5):#多个大的连通区域\n",
    "    if areas_sorted==[]:\n",
    "        return 'no_black_contour'\n",
    "        \n",
    "    topK_num_sum = sum(areas_sorted[i] if x>areas_sorted[0]*0.8 else 0 for (i, x) in enumerate(areas_sorted))#yes 0.8 is a magic number\n",
    "    topK_idxs = [i for (i, x) in enumerate(areas_sorted)  if x>areas_sorted[0]*0.8 ]\n",
    "    topK_num_cnt = len(topK_idxs)\n",
    "    #print('topK_num_cnt:', topK_num_cnt)\n",
    "    \n",
    "    if topK_num_sum/topK_num_cnt>topK_average_threshold:#超过了阈值（经验值3.5），说明存在很大的连通区域\n",
    "        for topK_idx in topK_idxs:\n",
    "            topK_box = boxs_hor_sorted[topK_idx]\n",
    "            black_area_rate = black_area_in_box(bin_img, topK_box)\n",
    "            #print(black_area_rate)#黑色连通域的黑色像素比例可能高达0.98\n",
    "            if black_area_rate>0.999:#敏感信息遮挡的话是纯黑背景，而且矩形方框是平行于图像，故黑色面积和连通区域比例是100%\n",
    "                return 'sensitive_info'\n",
    "            elif is_black_stripe(bin_img, topK_box, is_stripe_threshold=7)==1:\n",
    "                return 'has_black_stripe'\n",
    "            else:\n",
    "                return 'has_black_contour'\n",
    "    else:\n",
    "        return 'no_black_contour'\n",
    "\n",
    "def black_area_in_box(bin_img, box_hor):\n",
    "    x1,y1=box_hor[0]\n",
    "    x2,y2=box_hor[2]\n",
    "    \n",
    "    blk_img = bin_img[y1:y2, x1:x2]\n",
    "    img_height, img_width = blk_img.shape[:2]\n",
    "    return sum(sum(1-blk_img/255))/img_height/img_width\n",
    "\n",
    "def is_black_stripe(bin_img, box_hor, is_stripe_threshold=7):\n",
    "    x1,y1=box_hor[0]\n",
    "    x2,y2=box_hor[2]\n",
    "    \n",
    "    rect_length=max(abs(y2-y1),abs(x2-x1))\n",
    "    rect_width=min(abs(y2-y1),abs(x2-x1))\n",
    "    if rect_length/rect_width>is_stripe_threshold:#长宽差距很大，则是黑色分割条\n",
    "        #print('长宽差距很大')\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 no_black_contour\n",
      "1 has_black_stripe\n",
      "2 has_black_stripe\n",
      "3 has_black_stripe\n",
      "4 has_black_stripe\n",
      "5 has_black_stripe\n",
      "6 has_black_contour\n",
      "7 has_black_contour\n",
      "8 has_black_contour\n",
      "9 has_black_contour\n",
      "10 has_black_contour\n",
      "11 no_black_contour\n",
      "12 has_black_contour\n",
      "13 has_black_contour\n",
      "14 no_black_contour\n",
      "15 no_black_contour\n",
      "16 has_black_contour\n",
      "17 no_black_contour\n",
      "18 no_black_contour\n",
      "19 no_black_contour\n",
      "20 no_black_contour\n",
      "21 no_black_contour\n",
      "22 has_black_stripe\n",
      "23 has_black_stripe\n",
      "24 has_black_stripe\n",
      "25 has_black_stripe\n",
      "26 sensitive_info\n",
      "27 sensitive_info\n",
      "28 sensitive_info\n",
      "29 sensitive_info\n",
      "30 sensitive_info\n",
      "31 sensitive_info\n",
      "32 sensitive_info\n",
      "33 sensitive_info\n",
      "34 sensitive_info\n",
      "35 sensitive_info\n",
      "36 sensitive_info\n",
      "37 sensitive_info\n",
      "38 sensitive_info\n",
      "39 sensitive_info\n",
      "40 has_black_contour\n",
      "41 sensitive_info\n"
     ]
    }
   ],
   "source": [
    "for img_id in range(42):\n",
    "    img_name = 'img_'+str(1000000+img_id)+'.png'\n",
    "    img = cv2.imread(img_path + img_name)\n",
    "    \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    bin_threshold, bin_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "#     kernel_size = (int(img_height/500), int(img_width/150))\n",
    "#     kernel = np.ones(kernel_size,np.uint8)\n",
    "#     dilate_img = cv2.dilate(bin_img,kernel,iterations = 1)\n",
    "\n",
    "    areas_sorted, boxs_hor_sorted = get_large_contours(bin_img)\n",
    "    \n",
    "#     tmp_img = dilate_img - dilate_img\n",
    "#     cv2.drawContours(tmp_img,boxs_hor_sorted,-1,(100,100,100),5)\n",
    "#     PIL_img_show(tmp_img)\n",
    "    \n",
    "    classify_result = is_X_ray(bin_img, areas_sorted, boxs_hor_sorted)\n",
    "    print(img_id, classify_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 3]\n",
      "[1, 2, 3] [2, 1, 3]\n",
      "([2, 7], [0.9, 8.3], [11, 32]) (3, 2, 1)\n",
      "[[2, 7], [0.9, 8.3], [11, 32]] [3, 2, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.199999999999996"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[0.9,8.3],[11,32],[2,7]]\n",
    "b=[2,1,3]\n",
    "b_sorted=b.copy()\n",
    "print(b)\n",
    "b_sorted.sort()\n",
    "print(b_sorted, b)\n",
    "c=sorted(zip(a,b),key=lambda x:x[1], reverse=True) \n",
    "a, b=zip(*c)\n",
    "print(a,b)\n",
    "print(list(a), list(b))\n",
    "\n",
    "sum(sum(np.array(a)))\n",
    "\n",
    "print(sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2338 1653\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path + 'img_'+str(1000040)+'.png')\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_heigth, img_width = gray_img.shape[:2]\n",
    "print(img_heigth, img_width)\n",
    "\n",
    "\n",
    "bin_threshold, bin_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "PIL_img_show(gray_img)\n",
    "PIL_img_show(bin_img)\n",
    "\n",
    "# for x in range(img_width):\n",
    "#     print(gray_img.item(550, x), bin_img.item(550, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (int(img_heigth/500), int(img_width/150))\n",
    "kernel = np.ones(kernel_size,np.uint8)\n",
    "dilate_img = cv2.dilate(bin_img,kernel,iterations = 1)\n",
    "PIL_img_show(dilate_img)\n",
    "\n",
    "# for x in range(img_width):\n",
    "#     print(erosion_img.item(550, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n"
     ]
    }
   ],
   "source": [
    "#image,contours,hierarchy=cv2.findContours(erosion_img,1,2)\n",
    "\n",
    "# cv2.RETR_EXTERNAL表示只检测外轮廓\n",
    "# cv2.RETR_LIST检测的轮廓不建立等级关系\n",
    "# cv2.RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。\n",
    "# cv2.RETR_TREE建立一个等级树结构的轮廓。\n",
    "image, contours, hierarchy = cv2.findContours(dilate_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)#CHAIN_APPROX_SIMPLE\n",
    "\n",
    "tmp_img = dilate_img - dilate_img\n",
    "cv2.drawContours(tmp_img,contours,-1,(100,100,100),5)\n",
    "PIL_img_show(tmp_img)\n",
    "\n",
    "print(len(contours))\n",
    "areas=[]\n",
    "for cnt in contours:\n",
    "    areas.append( cv2.contourArea(cnt))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove largest one\n",
      "[0.03921235587624413, 0.042191726053115615, 0.04493519301950168, 0.05244914713125969, 0.05908064849268333, 0.061177565919220446, 0.07446678010989943, 2.4403750266920112, 2.752527397099893, 2.895309999535183]\n",
      "8.771292012177497 -241.17123218013361\n"
     ]
    }
   ],
   "source": [
    "#print(contours[areas.index(max(areas))])\n",
    "\n",
    "areas_sorted = areas.copy()\n",
    "areas_sorted.sort()\n",
    "areas_sorted = [x/(img_heigth*img_width)*100 for x in areas_sorted]\n",
    "if areas_sorted[-1]>99.5:# to remove the largest contours if the largest is the whole image.\n",
    "    print('remove largest one')\n",
    "    areas_sorted = areas_sorted[:-1]\n",
    "print(areas_sorted[-10:])\n",
    "\n",
    "s=0\n",
    "for x in range(img_heigth):\n",
    "    for y in range(img_width):\n",
    "        s+=erosion_img.item(x,y)\n",
    "print(sum(areas_sorted), 1-s/img_heigth/img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.04432617782325 6 True\n"
     ]
    }
   ],
   "source": [
    "topK_num_sum = sum(areas_sorted[i] if x>areas_sorted[-1]*0.8 else 0 for (i, x) in enumerate(areas_sorted))#yes 0.8 is a magic number\n",
    "topK_num_cnt = sum(1 if x>areas_sorted[-1]*0.8 else 0 for (i, x) in enumerate(areas_sorted))\n",
    "print(topK_num_sum, topK_num_cnt, topK_num_sum/topK_num_cnt>3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
