{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import pillowfight\n",
    "\n",
    "img_path = '../OCR_data/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIL_img_show(img):\n",
    "    Image.fromarray(img).show()\n",
    "\n",
    "def filte_contours(contours, hierarchy):#汉字的一个特点是文字内部有空洞，由此形成连通域，但是检测句子所在行的话应该去掉这部分\n",
    "    first_child = hierarchy[0][0][2]\n",
    "    next_child = first_child\n",
    "    all_children=[]\n",
    "    while(next_child!=-1):\n",
    "        all_children.append(next_child)\n",
    "        next_child = hierarchy[0][next_child][0]\n",
    "    contours_filtered = [contours[x] for x in all_children]\n",
    "    \n",
    "#     print(len(all_children), all_children)\n",
    "    return contours_filtered\n",
    "\n",
    "\n",
    "def get_likely_text_area(bin_img):\n",
    "    \n",
    "    img_height, img_width = bin_img.shape[:2]\n",
    "    \n",
    "    kernel_size = (int(img_height/300), int(img_width/1000))\n",
    "    kernel = np.ones(kernel_size,np.uint8)\n",
    "    dilate_img = cv2.dilate(bin_img,kernel,iterations = 1)\n",
    "    #PIL_img_show(dilate_img)\n",
    "\n",
    "    kernel_size = (int(img_height/400), int(img_width/80))\n",
    "    kernel = np.ones(kernel_size,np.uint8)\n",
    "    erosion_img = cv2.erode(dilate_img,kernel,iterations = 2)\n",
    "\n",
    "    #PIL_img_show(erosion_img)\n",
    "    \n",
    "    \n",
    "    image, contours, hierarchy = cv2.findContours(erosion_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)#CHAIN_APPROX_SIMPLE\n",
    "\n",
    "#     tmp_img = erosion_img-erosion_img\n",
    "#     cv2.drawContours(tmp_img,contours,-1,(100,100,100),5)\n",
    "#     PIL_img_show(tmp_img)\n",
    "\n",
    "#     print(len(contours))\n",
    "    contours_filtered = filte_contours(contours, hierarchy)\n",
    "#    print(len(contours_filtered))\n",
    "    areas=[]\n",
    "    rects=[]#矩形信息包括：矩形中心，高度，宽度，旋转角\n",
    "    boxs=[]#矩形信息包括：矩形四个点的坐标，经过rects信息计算而来，经过了计算把浮点数转化为图像坐标，矩形可以不是水平的。\n",
    "\n",
    "    for cnt in contours_filtered:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        areas.append(area)\n",
    "\n",
    "        rect = cv2.minAreaRect(cnt) # 得到最小外接矩形的（中心(x,y), (宽,高), 旋转角度）\n",
    "        rects.append(rect)\n",
    "\n",
    "        box = cv2.boxPoints(rect) # cv2.boxPoints(rect) for OpenCV 3.x 获取最小外接矩形的4个顶点\n",
    "        box = np.int0(box)\n",
    "        boxs.append(box)\n",
    "\n",
    "    tmp_img = gray_img.copy()\n",
    "    #tmp_img = erosion_img-erosion_img\n",
    "    cv2.drawContours(tmp_img,contours_filtered,-1,(100,100,100),5)\n",
    "    PIL_img_show(tmp_img)\n",
    "    \n",
    "    boxs_horizontal=[]#将boxs化为方向水平，但是如果句子是倾斜的则圈出的范围过于宽泛。\n",
    "    for box in boxs:\n",
    "        x1=min(box[0][0], box[1][0], box[2][0], box[3][0])\n",
    "        x2=max(box[0][0], box[1][0], box[2][0], box[3][0])\n",
    "        y1=min(box[0][1], box[1][1], box[2][1], box[3][1])\n",
    "        y2=max(box[0][1], box[1][1], box[2][1], box[3][1])\n",
    "        boxs_horizontal.append(np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2]]))\n",
    "\n",
    "#     print(len(boxs_horizontal))\n",
    "    return areas, boxs_horizontal, boxs, contours_filtered\n",
    "\n",
    "#输入：灰度图，因为要保护mask变量，需要二值化为非255的二值图。干脆封装起来避免用户输入的二值化图带有255\n",
    "#输出：文字区域的面积\n",
    "def get_text_area(gray_img):#使用swt算法挖掘文字区域，经过测试，该算法准确率极高\n",
    "    \n",
    "    img_heigth, img_width = gray_img.shape[:2]\n",
    "    \n",
    "    bin_threshold, bin_img = cv2.threshold(gray_img,0,100 ,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#此处取100，只要不取255就行，因为mask用的是255\n",
    "    \n",
    "    #将文字区域用黑色矩形框画出，非文字区域用白色画出\n",
    "    original_img_mask = np.uint8(np.ones((img_heigth,img_width))*255)\n",
    "    \n",
    "    bin_img_PIL_formate = Image.fromarray(bin_img)\n",
    "    \n",
    "    PIL_img_show(gray_img)\n",
    "    bin_img_PIL_formate.show()\n",
    "    \n",
    "    swt_out_img = pillowfight.swt(bin_img_PIL_formate, output_type=pillowfight.SWT_OUTPUT_ORIGINAL_BOXES)\n",
    "    \n",
    "    swt_out_img.show()\n",
    "    \n",
    "    swt_out_img = np.array(swt_out_img)[:, :, 0]#PIL Image 格式的图像是3通道的，取其中之一即可\n",
    "    #print(swt_out_img.shape)\n",
    "    mask_not_text_area=np.uint8(swt_out_img!=original_img_mask)#不相等的区域是文字区域\n",
    "    #print(mask_not_text_area.shape)\n",
    "    \n",
    "    #draw\n",
    "    #Image.fromarray(255*(1-mask_not_text_area)).show()\n",
    "    \n",
    "    \n",
    "    #mask矩阵求和即是文字区域的面积\n",
    "    swt_area_sum=sum(sum(np.uint16(mask_not_text_area)))#不用uint16的话会导致第一层sum‘溢出’\n",
    "    \n",
    "    return swt_area_sum\n",
    "\n",
    "def text_area_div_likely_text_area(bin_img, gray_img):\n",
    "    \n",
    "    areas, boxs_horizontal, boxs, contours_filtered = get_likely_text_area(bin_img)\n",
    "    if areas==[]:\n",
    "        return 1000000    #分母为0\n",
    "    else:\n",
    "        areas_sum = sum(areas)\n",
    "    \n",
    "    text_area_sum = get_text_area(gray_img)\n",
    "    \n",
    "    return text_area_sum/areas_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.724011518724172\n"
     ]
    }
   ],
   "source": [
    "for img_id in range(6,7):\n",
    "    img_name = 'img_'+str(1000000+img_id)+'.png'\n",
    "    img = cv2.imread(img_path + img_name)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_heigth, img_width = gray_img.shape[:2]\n",
    "    \n",
    "    bin_threshold, bin_img = cv2.threshold(gray_img,0,255 ,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    print(img_id, text_area_div_likely_text_area(bin_img, gray_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in range(0,42):\n",
    "    img_name = 'img_'+str(1000000+img_id)+'.png'\n",
    "    img = cv2.imread(img_path + img_name)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_heigth, img_width = gray_img.shape[:2]\n",
    "    \n",
    "    bin_threshold, bin_img = cv2.threshold(gray_img,0,100 ,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#此处不适合取255，因为mask用的是255\n",
    "\n",
    "    \n",
    "#     PIL_img_show(erosion_img)\n",
    "    areas, boxs_horizontal, boxs, contours_filtered = get_likely_text_area(bin_img)\n",
    "    #text_rate_metric = get_text_rate(bin_img, boxs_horizontal)\n",
    "    #print(img_id, text_rate_metric)\n",
    "    \n",
    "    original_img_mask = np.uint8(np.ones((img_heigth,img_width))*255)\n",
    "    \n",
    "    bin_img_PIL_formate = Image.fromarray(bin_img)\n",
    "    #bin_img_PIL_formate.show()\n",
    "    \n",
    "    swt_out_img = pillowfight.swt(bin_img_PIL_formate, output_type=pillowfight.SWT_OUTPUT_ORIGINAL_BOXES)\n",
    "    #swt_out_img.show()\n",
    "    \n",
    "    swt_out_img = np.array(swt_out_img)[:, :, 0]#PIL Image 格式的图像是3通道的，取其中之一即可\n",
    "    #print(swt_out_img.shape)\n",
    "    mask_not_text_area=np.uint8(swt_out_img!=original_img_mask)\n",
    "    #print(mask_not_text_area.shape)\n",
    "    \n",
    "    #draw\n",
    "    #Image.fromarray(255*(1-mask_not_text_area)).show()\n",
    "    \n",
    "    #draw contours\n",
    "    tmp_img = bin_img-bin_img\n",
    "    cv2.drawContours(tmp_img,contours_filtered,-1,(100,100,100),5)\n",
    "    #PIL_img_show(tmp_img)\n",
    "    \n",
    "    swt_area_sum=sum(sum(np.uint16(mask_not_text_area)))\n",
    "    print(img_id, '文字区域面积/连通域面积：%2.4f'%(swt_area_sum/sum(areas)))\n",
    "    \n",
    "#     for box_hor in boxs_horizontal:\n",
    "        \n",
    "#         x1,y1=box_hor[0]\n",
    "#         x2,y2=box_hor[2]\n",
    "#         split_img = bin_img[y1:y2, x1:x2]\n",
    "#         img_x, img_y = split_img.shape[:2]\n",
    "        \n",
    "#         split_img_PIL_formate=Image.fromarray(split_img)\n",
    "#         split_img_PIL_formate.show()\n",
    "        \n",
    "        \n",
    "#         original_img_mask = np.uint8(np.ones((img_x,img_y))*255)\n",
    "#         #SWT_OUTPUT_BW_TEXT\n",
    "#         #SWT_OUTPUT_GRAYSCALE_TEXT\n",
    "#         #SWT_OUTPUT_ORIGINAL_BOXES\n",
    "#         swt_out_img = pillowfight.swt(split_img_PIL_formate, output_type=pillowfight.SWT_OUTPUT_ORIGINAL_BOXES)\n",
    "#         swt_out_img.show()\n",
    "        \n",
    "#         swt_out_img = np.array(swt_out_img)[:,:,0]\n",
    "#         #print(swt_out_img.shape)\n",
    "#         mask_not_text_area=np.uint8(swt_out_img==original_img_mask)\n",
    "#         #print(mask_not_text_area.shape)\n",
    "#         Image.fromarray(255*mask_not_text_area).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for cnt in contours_filtered:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    a.append(area)\n",
    "    \n",
    "a.sort()\n",
    "print(a)\n",
    "print(areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(sum(np.uint16(mask_not_text_area),0),1))\n",
    "\n",
    "a=sum(mask_not_text_area)\n",
    "random.choice(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path + 'img_'+str(1000017)+'.png')\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_heigth, img_width = gray_img.shape[:2]\n",
    "print(img_heigth, img_width)\n",
    "\n",
    "\n",
    "bin_threshold, bin_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# PIL_img_show(gray_img)\n",
    "PIL_img_show(bin_img)\n",
    "\n",
    "kernel_size = (int(img_heigth/400), int(img_width/1000))\n",
    "kernel = np.ones(kernel_size,np.uint8)\n",
    "dilate_img = cv2.dilate(bin_img,kernel,iterations = 1)\n",
    "PIL_img_show(dilate_img)\n",
    "\n",
    "kernel_size = (int(img_heigth/400), int(img_width/80))\n",
    "kernel = np.ones(kernel_size,np.uint8)\n",
    "erosion_img = cv2.erode(dilate_img,kernel,iterations = 2)\n",
    "PIL_img_show(erosion_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#image,contours,hierarchy=cv2.findContours(erosion_img,1,2)\n",
    "\n",
    "# cv2.RETR_EXTERNAL表示只检测外轮廓\n",
    "# cv2.RETR_LIST检测的轮廓不建立等级关系\n",
    "# cv2.RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。\n",
    "# cv2.RETR_TREE建立一个等级树结构的轮廓。\n",
    "image, contours, hierarchy = cv2.findContours(erosion_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)#CHAIN_APPROX_SIMPLE\n",
    "\n",
    "tmp_img = erosion_img-erosion_img\n",
    "cv2.drawContours(tmp_img,contours,-1,(100,100,100),5)\n",
    "PIL_img_show(tmp_img)\n",
    "\n",
    "print(len(contours))\n",
    "contours_filtered = contours_filter(contours, hierarchy)\n",
    "print(len(contours_filtered))\n",
    "areas=[]\n",
    "rects=[]#矩形信息包括：矩形中心，高度，宽度，旋转角\n",
    "boxs=[]#矩形信息包括：矩形四个点的坐标，经过rects信息计算而来，经过了计算把浮点数转化为图像坐标，矩形可以不是水平的。\n",
    "\n",
    "for cnt in contours_filtered:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    areas.append(area)\n",
    "    \n",
    "    rect = cv2.minAreaRect(cnt) # 得到最小外接矩形的（中心(x,y), (宽,高), 旋转角度）\n",
    "    rects.append(rect)\n",
    "    \n",
    "    box = cv2.boxPoints(rect) # cv2.boxPoints(rect) for OpenCV 3.x 获取最小外接矩形的4个顶点\n",
    "    box = np.int0(box)\n",
    "    boxs.append(box)\n",
    "\n",
    "tmp_img = erosion_img-erosion_img\n",
    "cv2.drawContours(tmp_img,boxs,-1,(100,100,100),5)\n",
    "PIL_img_show(tmp_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxs_horizontal=[]#将boxs化为方向水平，但是如果句子是倾斜的则圈出的范围过于宽泛。\n",
    "for box in boxs:\n",
    "    x1=min(box[0][0], box[1][0], box[2][0], box[3][0])\n",
    "    x2=max(box[0][0], box[1][0], box[2][0], box[3][0])\n",
    "    y1=min(box[0][1], box[1][1], box[2][1], box[3][1])\n",
    "    y2=max(box[0][1], box[1][1], box[2][1], box[3][1])\n",
    "    boxs_horizontal.append(np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2]]))\n",
    "    \n",
    "print(len(boxs_horizontal))\n",
    "\n",
    "cv2.drawContours(gray_img,boxs_horizontal,-1,(100,100,100),5)\n",
    "PIL_img_show(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_point_cnt=0\n",
    "large_not_text_cnt=0\n",
    "small_not_text_cnt=0\n",
    "all_text_str=[]\n",
    "all_ROI_area_rate=[]\n",
    "text_rate_metric=0\n",
    "\n",
    "for idx, box_horizontal in enumerate(boxs_horizontal):\n",
    "    x1,y1=box_horizontal[0]\n",
    "    x2,y2=box_horizontal[2]\n",
    "    img_ROI = bin_img[y1:y2, x1:x2]\n",
    "    ROI_area = (x2-x1)*(y2-y1)\n",
    "    ROI_area_rate = ROI_area/img_heigth/img_width\n",
    "    \n",
    "    \n",
    "    if ROI_area/img_heigth/img_width<0.0005:#是小的噪点，不是中文或字母\n",
    "        small_point_cnt+=1\n",
    "    elif ((sum(sum(1-img_ROI/255)))/ROI_area)>0.7:#黑色部分太大，属于大片黑色非文字区域\n",
    "        large_not_text_cnt+=1\n",
    "    else:\n",
    "        text_str = pytesseract.image_to_string(Image.fromarray(img_ROI), lang='chi_sim')\n",
    "        if text_str=='' or text_str ==' ' or text_str=='\\t':# (len(text_str)<=3 and '\\t' in text_str):\n",
    "            small_not_text_cnt+=1\n",
    "        else:\n",
    "            #print(idx, text_str, ROI_area_rate, ROI_area_rate)\n",
    "            all_text_str.append(text_str)\n",
    "            all_ROI_area_rate.append(ROI_area_rate)\n",
    "print(small_point_cnt, large_not_text_cnt, small_not_text_cnt)\n",
    "\n",
    "ROI_area_weights=np.array(all_ROI_area_rate/sum(all_ROI_area_rate))\n",
    "all_test_length=[len(x) for x in all_text_str]\n",
    "length_div_area=np.array(all_test_length)/np.array(all_ROI_area_rate)\n",
    "\n",
    "text_rate_metric = np.mean((length_div_area-length_div_area.mean())**2*ROI_area_weights)\n",
    "print(text_rate_metric)\n",
    "\n",
    "# for i in range(len(all_text_str)):\n",
    "#     text_rate_metric+=len(all_text_str[i])/all_ROI_area_rate[i]*ROI_area_weights[i]\n",
    "\n",
    "# print(text_rate_metric/len(all_text_str))\n",
    "print(all_text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_div_area=np.array(all_test_length)/np.array(all_ROI_area_rate)\n",
    "print(length_div_area)\n",
    "print(ROI_area_weights)\n",
    "print(length_div_area.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "for idx, box_horizontal in enumerate(boxs_horizontal):\n",
    "    x1,y1=box_horizontal[0]\n",
    "    x2,y2=box_horizontal[2]\n",
    "    x.append((x2-x1)*(y2-y1))\n",
    "print(np.sort(x)/img_heigth/img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contours[areas.index(max(areas))])\n",
    "print(areas.index(max(areas)))\n",
    "\n",
    "areas_sorted = areas.copy()\n",
    "areas_sorted.sort()\n",
    "areas_sorted = [x/(img_heigth*img_width)*100 for x in areas_sorted]\n",
    "if areas_sorted[-1]>99.5:# to remove the largest contours if the largest is the whole image.\n",
    "    print('remove the largest one if it is the whole image')\n",
    "    areas_sorted = areas_sorted[:-1]\n",
    "print(areas_sorted[-10:])\n",
    "\n",
    "s=0\n",
    "for x in range(img_heigth):\n",
    "    for y in range(img_width):\n",
    "        s+=erosion_img.item(x,y)\n",
    "print(sum(areas_sorted), 1-s/img_heigth/img_width, img_heigth, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.aruco_CharucoBoard()\n",
    "retval=cv2.aruco_CharucoBoard.getChessboardSize(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
